            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

James Knight        <jk1015@ic.ac.uk>
Max Smith           <mws15@ic.ac.uk>
Inusha Hapuarachchi <ih1115@ic.ac.uk>
Paul Crestez        <pmc15@ic.ac.uk>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (5 marks)
>> Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
    ...
    int base_priority;
    Stores the priority a thread has ignoring all donations. Returned to when
    there is no higher donation after releasing a lock.

    struct lock* waiting_on;
    The lock that the thread is currently attempting to acquire. Used in
    increase_lock_priority to access lock for nested donation.

    struct list acquired_locks;
    Locks acquired by the thread. Upon releasing a lock it is removed and
    priority is set to the max of base_priority and the acquired_locks
    priorities.
    ...
  };

struct lock
  {
    ...
    struct semaphore access_sema;
    Used to control access to members of the lock, preventing race conditions.

    int priority;
    Stores the maximum priority of any thread waiting on the lock. Donated to
    current lock holder and nested locks if the holder's priority is lower.

    struct list_elem elem;
    Allows lock to be stored in a list. Used specifically for
    thread.acquired_locks.

  };

static enum intr_level lock_release_intr_level; (synch.c)
lock_release must disable interrupts before calling sema_up, this stores the
intr_level prior to this so that sema_up can return to it before exiting.

static bool lock_release_intr_flag; (synch.c)
flag checked in sema_up to see if it was called from lock_release so it can
properly reset intr_level.

bool yield_on_intr_enable; (thread.c)
Flag denoting the current thread should yield once interrupts are enabled.
Set by thread_unblock to ensure highest priority thread runs without preempting
the current thread.

>> A2: (10 marks)
>> Explain the data structure used to track priority donation.
>> Give a diagram that illustrates a nested donation in your structure.

To track priority donation, we modified the existing lock and thread structs.
Each lock tracks the highest priority of the threads that are waiting on it. We
also use the existing list of waiters and the pointer to the current holder.
Each thread now contains it's original priority; a list of locks that the thread
has acquired; as well a pointer to the lock that the thread is currently waiting
on, if the thread is waiting.
When a high priority thread acquires a lock and tries to donate its priority,
the acquire_lock function calls the donate_priority function on the lock. If the
new priority is higher than the lock's current priority, the lock's priority if
updated. Then, if this priority is updated, the function modifies the holder
thread's priority through the lock's pointer to its holder, again provided the
new priority is higher than the thread's current priority. In a nested donation,
the function accesses the lock that the thread is waiting on through the
thread's pointer to it, and recursively calls the function on that lock. An
example of this can be seen in the diagram below: the function returns when
either the lock or thread has a higher priority than that being donated, as
shown, or it donates to a thread not waiting on a lock.
When a lock is released, lock_release iterates through the lock holder's list of
acquired locks. The priority field of these locks is used to determine the new
highest priority, which the threads priority is set to if it is higher than the
original priority. The lock is removed from the thread's list of acquired locks.
When a thread acquires the lock the lock is pushed to the thread's list of
acquired locks. It then iterates through the lock's list of waiters, finding the
highest priority thread, and updating the lock's priority to that. The lock's
holder is then updated to the new thread.

+-----------+
|   Lock    |
|-----------|   +-----------+
|  holder   |---|  Thread   |
|           |   |-----------|   +-----------+
|priority=x1|   |waiting_on |---|   Lock    |
+-----------+   |           |   |-----------|                   +-----------+
 |              |priority=x2|   |  holder   |----   ....    ----|Lock/Thread|
 |              +-----------+   |           |                   |-----------|
 |                              |priority=x3|                   |priority=xn|
 |                              +-----------+                   +-----------+
 |                                |
 |    +--------------+            |
 +--- | Lock |   P   |            |
      | ------------ |----+       |
      |donate(Lock,P)|    |       |
      +--------------+    |       |   +--------------+         +--------------+
                          |       +-- | Lock |   P   |         | Lock |   P   |
                          |           | ------------ |         | ------------ |
                          +---------- |donate(Lock,P)|---...---|donate(Lock,P)|
                                      +--------------+         +--------------+

                        x1, x2, ... , x(n-1) < P <= xn

                                  --Result--
+-----------+
|   Lock    |
|-----------|   +-----------+
|  holder   |---|  Thread   |
|           |   |-----------|   +-----------+
|priority=P |   |waiting_on |---|   Lock    |
+-----------+   |           |   |-----------|                   +-----------+
                |priority=P |   |  holder   |----   ....    ----|Lock/Thread|
                +-----------+   |           |                   |-----------|
                                |priority=P |                   |priority=xn|
                                +-----------+                   +-----------+


---- ALGORITHMS ----

>> A3: (5 marks)
>> How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
The behaviour of sema_up remains the same except that list_max is called on the
semaphore's waiters to return the thread to be woken, rather than popping the
front of the list. list_max uses an ordering function which causes it to return
the thread with highest priority as its result, this thread is then removed from
the list of waiters and sema_up continues to execute as usual.
A lock contains a semaphore and relies on this to decide which thread will be
woken, so changing the behaviour of sema_up changes the behaviour of locks in
the same way.
A condition variable contains a list of semaphores each semaphore having only
one waiter. The behaviour of cond_signal is again mostly unchanged except that
rather than popping the first semaphore from the list it instead uses a list_max
which returns the semaphore containing the highest priority thread.

>> A4: (5 marks)
>> Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
Any call to lock_acquire calls the donate_priority function, this function takes
two arguments the lock being acquired and the priority of the acquiring thread
(referred to as PRI). For a donation to occur PRI must be higher than the
current priority of the lock, the lock must be held and PRI must also be higher
than the priority of the holder. If these conditions hold then the priority of
the lock is updated to the new, higher, priority PRI and the priority of the
lock holder is also updated to PRI. If the lock holder itself is waiting on
another lock then a nested donation occurs, the donate_priority function is
recursively called with the lock on which the holder is waiting and PRI as its
arguments. Before a nested donation occurs the access_sema of the current lock
is upped, this is because we will not be touching this lock again during the
recursive call.


>> A5: (5 marks)
>> Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
When lock_release is called the lock upon which it is called first has its
holder set to NULL. Following this the function itterates through the
acquired_locks of the calling thread, removing the released lock and finding the
maximum priority value of the other locks. Before the priority of the thread is
updated to this maximum value interrupts must be disabled, this is to prevent an
interrupt causing a priority inversion by calling schedule after the priority is
lowered but before the semaphore of the lock is upped, a flag is set to ensure
the interrupt level is properly restored. The priority of the thread is then set
to the previously calculated maximum value of its remaining locks and its base
priority. Finally the semaphore of the lock is upped and the higher-priority
thread is awoken.

When the higher priority thread is scheduled it continues executing
lock_acquire, its waiting_on is set back to NULL and the list of waiters on the
lock is itterated through to find the priority of the highest priority thread
still waiting on it, the priority of the lock is set to this value. The new
priority of the lock is guaranteed to be less than or equal to the priority of
the currently running thread so no donations need occur. The holder of the lock
is then updated to be the currently running thread and lock_acquire returns.




---- SYNCHRONIZATION ----

>> A6: (5 marks)
>> Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
A race condition in thread_set_priority requires that an interrupt occurs during
the execution of thread_set_priority. There are two possible race conditions
when this occurs, either a yield occurs to a thread which causes a priority
donation to the interrupted thread or since current_thread remains unchanged in
an interrupt the interrupt itself calls thread_set_priority. Both cases modify
the priority of the original thread, this modification will immediately be
overwritten when we return to the original thread and finish executing
thread_set_priority.
The first of the two cases could be solved by using a lock to prevent the thread
to which we yielded donating a priority until thread_set_priority is complete,
however the second case cannot be solved using a lock since interrupts are
unable to acquire locks. Therefore our implementation must avoid a race by
disabling interrupts for the duration of thread_set_priority.


---- RATIONALE ----

>> A7: (5 marks)
>> Why did you choose this design?  In what ways is it superior to
>> another design you considered?
When designing our solution the usage of space in the thread struct was a large
concern as a thread is limited to a single 4kb page and so increasing the size
of the struct limits the possible stack size. One design we considered was to
construct an array of 64 lists each list containing locks of a different
priority from 0-63, this would have been used in place of the current
acquired_locks list, and would have given significatly faster access times
with only the small complication of having to move a lock to a different list
whenever its priority changed. Ultimately however we chose the simpler data
structure of a single list, this is because the array suggested would have had
size 64*sizeof(struct list) = 512B when using 4 Byte pointers, this is one
eighth of the total size of a page, completely unwarranted for a single data
structure. Another benefit of our focus on space was additional scalability, if
we wanted more granularity in the priority by adding additional priority levels
our design could do so without increasing space usage, whereas the array method
would require an additional 8 Bytes per level, giving a hard cap of 512 priority
levels.

//TODO Simplicity?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (5 marks)
>> Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: (5 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
0       0   0   0  63  61  59     A
4       4   0   0  62  61  59     A                        
8       8   0   0  61  61  59     B                          
12      8   4   0  61  60  59     A                          
16     12   4   0  60  60  59     B                          
20     12   8   0  60  59  59     A    
24     16   8   0  59  59  59     C                           
28     16   8   4  59  59  58     B                           
32     16  12   4  59  58  58     A                           
36     20  12   4  58  58  58     C

>> B3: (5 marks)
>> Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behaviour of your scheduler?
The term "round robin" was ambiguous. For the example above, when the timer 
ticks reaches 8, there are 2 threads that have maximum priority. Thread A
was the last one to run. Therefore, B should be the next thread scheduled
to run. The problem also appears at tick 24, where we can choose out of 3
available threads. Since thread A was the last to run, but C was the first one
in the 59 priority queue, C should run first, then B and then A. This 
behavious is somewhat unintuitive.


>> B4: (5 marks)
>> How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> B5: (5 marks)
>> Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.

>> B6: (5 marks)
>> The assignment explains arithmetic for fixed-point mathematics in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point mathematics, that is, an abstract
>> data type and/or a set of functions or macros to manipulate
>> fixed-point numbers, why did you do so?  If not, why not?S
